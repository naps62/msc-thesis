\documentclass[main.tex]{subfiles}
\begin{document}

\chapter{Introduction}

\section{Context}

Heterogeneous platforms are increasingly popular for high performance computing, with an increasing number of supercomputers taking advantage of accelerating devices in addition to the already powerful traditional \cpus, to provide higher performance at lower costs. These accelerators are not as general-purpose as a conventional \cpu, but have features that make them more suitable to specific, usually highly parallel tasks, and as such are useful as coprocessors that complement the work of conventional systems.

Moore's law \cite{moore1965cramming,moore1975progress} predicted in 1975 that the performance of microprocessors would double every two years. That expectation has since driven the development of microprocessors. The number of transistors, and high clock frequencies of today's microprocessors is near the limit of power density, introducing problems such as heat dissipation and power consumption. Facing this limitations, research focus was driven towards multi-core solutions.

This marked the beginning of the multi-core era. While multi-core systems were already a reality, it was not until this point that they reached mainstream production, and parallel paradigms began to emerge as more general-purpose solutions.

In addition to regular \cpus, other types of devices also emerged as good computational alternatives. In particular, the first \gpus supporting general purpose computing were introduced by \nvidia early this century.

These devices gradually evolved from specific hardware dedicated to graphics rendering, to fully featured general programming devices, capable of massive data parallelism and performance, and sometimes provide lower power consumptions.
They enable the acceleration of highly parallel tasks, being more efficient than \cpus on specific tasks, but also more specialized. The usage of \gpus for general computing has been named \ac{GPGPU}, and has since become an industry standard.
As of 2013, over 30 of the TOP500's\footnote{A list of the most powerful supercomputers in the world, updated twice a year (\url{http://www.top500.org/})} list were powered by \gpus. This increased usage is motivated by the effectiveness of these devices for general-purpose computing.

Other types of accelerators recently emerged, like the recent Intel \mic architecture, and while all of them differ from the traditional \cpu architecture, they also differ between themselves, providing different hardware specifications, along with different memory and programming models.

Development of applications targeting these coprocessor devices tends to be harder, or at least different from conventional programming. One has to take into account the differences of the underlying architecture, as well as the programming model being used, in order to produce code that is not only correct, but also efficient. And efficiency for one coprocessor might have a different set of requirements or rules that are inadequate to a different one. As a result, developers need to take into account the characteristics of each different device they are using within their applications, if they aim to fully take advantage of them. Usually, the task of producing the most efficient code for a single platform is very time consuming, and requires thorough understanding of the architecture details, In addition, the inherent parallel nature of these accelerators introduces yet another difficulty layer.

Each device can also be programmed in various ways, ranging from programming models such as \cuda, \opencl or \texttt{pthreads}\footnote{POSIX Threads: The standard thread management library for most UNIX systems} to higher level libraries like \openmp or \openacc. Each of these provides a different method of writing parallel programs, and has a different level of abstraction about the underlying architecture.

The complexity increases even further when it is considered that multiple accelerators might be simultaneously used. This aggravates the already existing problems concerning workload distribution, scheduling, and communication / data transfers.

Recent studies \cite{lee2010debunking,bordawekar2010believe} also show that overall speedups when using accelerators should not be expected to be as high as initially suggested. These studies show that, while the measured speedups of multiple applications ported to \gpus were real, the actual reason was not the better overall performance of the device, but actually the poorly optimized original \cpu code. Actually, when code is better designed, similar speedups can be obtained in traditional \cpus. This indicates that accelerators should not be regarded as the only source of high computational power, but rather as an additional resource, and the whole system should be appropriately used for better efficiency.

Current coprocessor devices are most commonly used as accelerators (in the context of general-computing), in a system where at least one \cpu manages the main execution flow, and delegates specific tasks to the remaining computing resources. A system that uses different computing units is commonly referred to as an heterogeneous platform, here referred to as a \hetplat. These systems become particularly noticeable in the TOP500 ranking, where an increasing number of top-rated systems are heterogeneous.

Much like the phenomenon seen at the start of the multi-core era, a new paradigm shift must happen to efficiently use a \hetplat. An even greater level of complexity is introduced, since one has to consider not only the multiple different architectures and programming models being used, but also the distribution of both work and data. Current \hetplats are distributed systems, since each computing accelerator device usually has its own memory hierarchy. As much as a given task may be fast on a given device, the required data transfers to offload such task may add an undesirable latency to the process, and is currently one of the highest performance bottlenecks of this approach.

Even within a single device, memory hierarchy usage can have a large impact on performance. In a \acs{NUMA} system, although each device can transparently access all memory nodes, access times will be dependent on where the requested data is pinned. Performance problems arise from this if one considers the multiple \cpu devices as one single multi-core \cpu. Instead, the topology of the system can be considered when assigning tasks to each individual processing unit, and data transferred accordingly, to avoid expensive memory transactions.

Code efficiency is also becoming extremely volatile, as each new system that emerges usually requires architecture-specific optimizations, making previous code obsolete in terms of performance. There is an increasing need for a unified solution that allows developers to keep focuses on the algorithmic issues, and automate these platform-specific issues, which present a barrier to the development of code targeting \hetplats.

Several frameworks have been developed in recent years to address these issues and to allow developers to abstract themselves from the underlying system. These frameworks usually manage the multiple resources of the system, treating both \cpus and coprocessors as generic computing devices that can execute tasks, and employ a scheduler to efficiently distribute data and workload. Memory management is also a key factor, with memory transfers playing a significant role in today's coprocessor efficiently.

Among these frameworks it is worth to mention MDR \cite{linderman2008merge}, Qilin \cite{luk2009qilin}, \starpu \cite{augonnet2011starpu} and \gama \cite{joao2012gama}. This dissertation focuses mostly on \starpu, with an overview and a comparative assessment with \gama.

These frameworks tend to encapsulate work by explicitly use the terms of task and data dependencies, and employ a task scheduler to assign data and workloads to the available resources.
The scheduler is considered one of the key features of these  frameworks. It may take into account multiple different factors to decide when and where to run the submitted tasks. These factors can range from the architectural details of the detected resources, to the measured performance of each task on each device, which can be supported by a history-based performance model.

\subfile{tex/110_motivation}
\subfile{tex/120_organization}

\end{document}
