\documentclass[main.tex]{subfiles}

\begin{document}

\subsection{CUDA} \label{section:impl_cuda}

Following the \cpu implementation, it was also desirable to produce a \cuda based implementation. Like the previous one, this served the purpose of producing an implementation similar to the original, but havint task code shared with the future \starpu version, and minimize any details that would be different about the implementation.

The goal of this version is to port as much as possible of the \cpu task code to \cuda. However, as explained previously (in \cref{section:kernels,section:impl_cpu}), some of the tasks are not parallelizable, and consequentely, not adequate to massively parallel devices. This means that these tasks were ketp running on the \cpu. The obvious consequence of this is that a full iteration of the algorithm is not capable of running entirely on a \gpu, requiring memory transfers in between to solve data dependencies.

The most problematic drawback of this decision is about the \textbf{Rebuild Lookup Table} task. Running this task on \cpu will likely have a very noticeable impact on performance, since it requires to transfer the generated hit points from the \gpu to the \cpu, and later copy the generated hash table back to the \gpu.

\end{document}
